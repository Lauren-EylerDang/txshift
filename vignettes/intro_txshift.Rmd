---
title: "Targeted Learning with Stochastic Treatment Regimes"
author: "[Nima Hejazi](https://nimahejazi.org) and [David
  Benkeser](https://www.benkeserstatistics.com/)"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
bibliography: vignette-refs.bib
vignette: >
  %\VignetteIndexEntry{Targeted Learning with Stochastic Treatment Regimes}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, echo=FALSE}
options(scipen=999)
```

## Introduction

Stochastic treatment regimes present a relatively simple manner in which to
assess the effects of continuous treatments by way of parameters that examine
the effects induced by the counterfactual shifting of the observed values of a
treatment of interest. Here, we present an implementation of a new algorithm for
computing targeted minimum loss-based estimates of treatment shift parameters
defined based on a shifting function $d(A,W)$. For a technical presentation of
the algorithm, the interested reader is invited to consult @diaz2017stochastic.
For additional background on Targeted Learning and previous work on stochastic
treatment regimes, please consider consulting @vdl2011targeted,
@vdl2017targeted, and @munoz2012population.

To start, let's load the packages we'll use and set a seed for simulation:

```{r setup}
library(tidyverse)
library(data.table)
library(condensier)
library(sl3)
library(txshift)
set.seed(429153)
```

---

## Data and Notation

1. Start with a simple additive shift -- i.e., $d(a,w) = a + \delta$ if
   $a < u(w) - \delta$ or $d(a, w) = a$ if $a \geq u(w) - \delta$.

2. The additive shift will have support everywhere (i.e.,
   $a < u(w)$ is true everywhere).

3. The data structure that we know and love $O = (W, A, Y)$.

### Simulate Data

```{r}
# simulate simple data for tmle-shift sketch
n_obs <- 1000  # number of observations
n_w <- 1  # number of baseline covariates
tx_mult <- 2  # multiplier for the effect of W = 1 on the treatment

## baseline covariate -- simple, binary
W <- as.numeric(replicate(n_w, rbinom(n_obs, 1, 0.5)))

## create treatment based on baseline W
A <- as.numeric(rnorm(n_obs, mean = tx_mult * W, sd = 1))

# create outcome as a linear function of A, W + white noise
Y <- A + W + rnorm(n_obs, mean = 0, sd = 1)

# shift parameter
delta <- 0.5
```

---

## Methodology

### Estimating Stochastic Interventions Effects with Generalized Linear Models

The simplest way to compute the TML estimator for the stochastic treatment
regime is to fit each of the major constituent parts (nuisance parameters) of
the estimator with generalized linear models. To do this, one may merely call
the `tmle_shifttx` function, providing the standard inputs listed below...

```{r}
tmle_glm_shift_1 <- tmle_txshift(W = W, A = A, Y = Y, delta = delta,
                                 fluc_method = "standard",
                                 ipcw_fit_args = NULL,
                                 g_fit_args = list(fit_type = "glm", nbins = 20,
                                                   bin_method = "dhist",
                                                   bin_estimator = speedglmR6$new(),
                                                   parfit = FALSE),
                                 Q_fit_args = list(fit_type = "glm",
                                                   glm_formula = "Y ~ .")
                                )
summary(tmle_glm_shift_1)
```

When computing any such TML estimator, we may, of course, vary the regressions
used in fitting the nuisance parameters; however, an even simpler variation is
to fit the step for the fluctuation submodels with a _weighted_ method, simply
weighting each observation by the so-called "clever" covariate rather than using
such a covariate directly in the regression fit. Please consult [INSERT REF] for
details on potential benefits this approach may have.

```{r}
tmle_glm_shift_2 <- tmle_txshift(W = W, A = A, Y = Y, delta = delta,
                                 fluc_method = "weighted",
                                 ipcw_fit_args = NULL,
                                 g_fit_args = list(fit_type = "glm", nbins = 20,
                                                   bin_method = "dhist",
                                                   bin_estimator = speedglmR6$new(),
                                                   parfit = FALSE),
                                 Q_fit_args = list(fit_type = "glm",
                                                   glm_formula = "Y ~ .")
                                )
summary(tmle_glm_shift_2)
```

### Interlude: Constructing Super Learners with `sl3`

```{r}
# SL learners to be used for most fits (e.g., IPCW, outcome regression)
lrnr_lib <- make_learner_stack("Lrnr_mean", "Lrnr_glm_fast",
                               "Lrnr_randomForest")
sl_lrn <- Lrnr_sl$new(learners = lrnr_lib, metalearner = Lrnr_nnls$new())

# SL learners for conditional densities to be used for the propensity score fit
lrnr_dens_lib <- make_learner_stack(list("Lrnr_condensier", nbins = 35,
                                          bin_estimator = Lrnr_mean$new(),
                                          bin_method = "equal.len",
                                          pool = FALSE),
                                    list("Lrnr_condensier", nbins = 25,
                                          bin_estimator = Lrnr_glm_fast$new(),
                                          bin_method = "equal.len",
                                          pool = FALSE)
                                   )
sl_lrn_dens <- Lrnr_sl$new(learners = lrnr_dens_lib,
                           metalearner = Lrnr_solnp_density$new())
```

### Estimating Stochastic Interventions Effects with Super Learners

Using the framework provided by the `sl3` package, the nuisance parameters of
the TML estimator may be fit with ensemble learning, using the cross-validation
framework of the Super Learner algorithm of [INSERT REF].

```{r}
tmle_sl_shift_1 <- tmle_txshift(W = W, A = A, Y = Y, delta = delta,
                                fluc_method = "standard",
                                ipcw_fit_args = NULL,
                                g_fit_args = list(fit_type = "sl",
                                                  sl_lrnrs = sl_lrn_dens),
                                Q_fit_args = list(fit_type = "sl",
                                                  sl_lrnrs = sl_lrn)
                               )
summary(tmle_sl_shift_1)
```

As before, we may vary the regression for the submodel fluctuation procedure by
weighting each observation by the value of the so-called clever covariate rather
than using such an auxiliary covariate directly in the regression procedure:

```{r}
tmle_sl_shift_2 <- tmle_txshift(W = W, A = A, Y = Y, delta = delta,
                                fluc_method = "weighted",
                                ipcw_fit_args = NULL,
                                g_fit_args = list(fit_type = "sl",
                                                  sl_lrnrs = sl_lrn_dens),
                                Q_fit_args = list(fit_type = "sl",
                                                  sl_lrnrs = sl_lrn)
                               )
summary(tmle_sl_shift_2)
```

### Statistical Inference for Targeted Maximum Likelihood Estimates

Recall that the asymptotic distribution of TML estimators has been studied
thoroughly:
$$\psi_n - \psi_0 = (P_n - P_0) \cdot D(\bar{Q}_n^*, g_n) + R(\hat{P}^*, P_0),$$
which, provided the following two conditions:

1. If $D(\bar{Q}_n^*, g_n)$ converges to $D(P_0)$ in $L_2(P_0)$ norm, and
2. the size of the class of functions considered for estimation of $\bar{Q}_n^*$
   and $g_n$ is bounded (technically, $\exists \mathcal{F}$ st
   $D(\bar{Q}_n^*, g_n) \in \mathcal{F}$ *__whp__*, where $\mathcal{F}$ is a
   Donsker class),

readily admits the conclusion that
$\psi_n - \psi_0 = (P_n - P_0) \cdot D(P_0) + R(\hat{P}^*, P_0)$.

Under the additional condition that the remainder term $R(\hat{P}^*, P_0)$
decays as $o_P \left( \frac{1}{\sqrt{n}} \right),$ we have that
$$\psi_n - \psi_0 = (P_n - P_0) \cdot D(P_0) + o_P \left( \frac{1}{\sqrt{n}}
 \right),$$
which, by a central limit theorem, establishes a Gaussian limiting distribution
for the estimator:

$$\sqrt{n}(\psi_n - \psi) \to N(0, V(D(P_0))),$$

where $V(D(P_0))$ is the variance of the efficient influence curve (canonical
gradient) when $\psi$ admits an asymptotically linear representation.

The above implies that $\psi_n$ is a $\sqrt{n}$-consistent estimator of $\psi$,
that it is asymptotically normal (as given above), and that it is locally
efficient. This allows us to build Wald-type confidence intervals in a
straightforward manner:

$$\psi_n \pm z_{\alpha} \cdot \frac{\sigma_n}{\sqrt{n}},$$

where $\sigma_n^2$ is an estimator of $V(D(P_0))$. The estimator $\sigma_n^2$
may be obtained using the bootstrap or computed directly via the following

$$\sigma_n^2 = \frac{1}{n} \sum_{i = 1}^{n} D^2(\bar{Q}_n^*, g_n)(O_i)$$

```{r}
(ci_shift <- confint(tmle_sl_shift_1))
```

---

## Advanced Usage: User-Specified Regressions

In some special cases it may be useful for the experienced use to compute the
treatment mechanism and outcome regressions separately (i.e., outside of the
`tmle_txshift` wrapper function), instead applying this user-facing wrapper only
to invoke the _targeting_ steps involved in computing the TML estimator for the
treatment shift parameter. In such cases, the optional arguments `gn_fit_spec`
and `Qn_fit_spec` may be utilized. We present a case of using these arguments in
the sequel

```{r}
# compute treatment mechanism (propensity score) externally
## first, initialize and produce the downshifted treatment data
gn_downshift <- rep(NaN, length(A))
gn_downshift[W == 1] <- dnorm(A[W == 1] - delta, mean = tx_mult, sd = 1)
gn_downshift[W == 0] <- dnorm(A[W == 0] - delta, mean = 0, sd = 1)
## next, initialize and produce the upshifted treatment data
gn_upshift <- rep(NaN, length(A))
gn_upshift[W == 1] <- dnorm(A[W == 1] + delta, mean = tx_mult, sd = 1)
gn_upshift[W == 0] <- dnorm(A[W == 0] + delta, mean = 0, sd = 1)
## then, initialize and produce the unshifted treatment data
gn_noshift <- rep(NaN, length(A))
gn_noshift[W == 1] <- dnorm(A[W == 1], mean = tx_mult, sd = 1)
gn_noshift[W == 0] <- dnorm(A[W == 0], mean = 0, sd = 1)
## finally, put it all together into an object like those prodcued internally
gn_out <- as.data.table(cbind(gn_downshift, gn_noshift, gn_upshift))
setnames(gn_out, c("downshift", "noshift", "upshift"))

# compute outcome regression externally
Qn_noshift <- W + A
Qn_upshift <- W + A + delta
Qn_out <- bound_scaling(as.data.table(cbind(Qn_noshift, Qn_upshift)),
                                      scale = "zero_one")
setnames(Qn_out, c("noshift", "upshift"))

# invoke the wrapper function only to apply the targeting step
tmle_shift_user <- tmle_txshift(W = W, A = A, Y = Y, delta = delta,
                                fluc_method = "standard",
                                ipcw_fit_args = NULL,
                                g_fit_args = list(fit_type = "glm"),
                                Q_fit_args = list(fit_type = "glm"),
                                gn_fit_spec = gn_out,
                                Qn_fit_spec = Qn_out)

```

---

## References


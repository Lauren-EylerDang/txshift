{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation of algorithm from Diaz and van der Laan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "condensier\n",
      "The condensier package is still in beta testing. Interpret results with caution.\n"
     ]
    }
   ],
   "source": [
    "library(condensier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rm(list = ls())\n",
    "set.seed(429153)\n",
    "n_obs <- 100\n",
    "n_w <- 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>W1</th><th scope=col>W2</th><th scope=col>W3</th><th scope=col>A</th><th scope=col>Y</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td> 1.3357904</td><td>-1.214200 </td><td> 0.7023165</td><td> 0.5581855</td><td> 0.5296480</td></tr>\n",
       "\t<tr><td> 0.5852906</td><td> 1.040991 </td><td>-0.7216398</td><td> 0.6135768</td><td> 0.5757955</td></tr>\n",
       "\t<tr><td> 1.3420567</td><td>-1.848015 </td><td>-1.0266263</td><td>-0.3826661</td><td>-0.3733951</td></tr>\n",
       "\t<tr><td> 0.7343200</td><td>-1.726326 </td><td>-0.5078887</td><td>-0.1823722</td><td>-0.1813630</td></tr>\n",
       "\t<tr><td>-0.1484268</td><td>-1.520334 </td><td> 1.2997251</td><td> 0.3935576</td><td> 0.3834764</td></tr>\n",
       "\t<tr><td> 1.7497752</td><td> 1.465439 </td><td>-0.6086780</td><td> 3.9513610</td><td>-0.7241274</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllll}\n",
       " W1 & W2 & W3 & A & Y\\\\\n",
       "\\hline\n",
       "\t  1.3357904 & -1.214200  &  0.7023165 &  0.5581855 &  0.5296480\\\\\n",
       "\t  0.5852906 &  1.040991  & -0.7216398 &  0.6135768 &  0.5757955\\\\\n",
       "\t  1.3420567 & -1.848015  & -1.0266263 & -0.3826661 & -0.3733951\\\\\n",
       "\t  0.7343200 & -1.726326  & -0.5078887 & -0.1823722 & -0.1813630\\\\\n",
       "\t -0.1484268 & -1.520334  &  1.2997251 &  0.3935576 &  0.3834764\\\\\n",
       "\t  1.7497752 &  1.465439  & -0.6086780 &  3.9513610 & -0.7241274\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "W1 | W2 | W3 | A | Y | \n",
       "|---|---|---|---|---|---|\n",
       "|  1.3357904 | -1.214200  |  0.7023165 |  0.5581855 |  0.5296480 | \n",
       "|  0.5852906 |  1.040991  | -0.7216398 |  0.6135768 |  0.5757955 | \n",
       "|  1.3420567 | -1.848015  | -1.0266263 | -0.3826661 | -0.3733951 | \n",
       "|  0.7343200 | -1.726326  | -0.5078887 | -0.1823722 | -0.1813630 | \n",
       "| -0.1484268 | -1.520334  |  1.2997251 |  0.3935576 |  0.3834764 | \n",
       "|  1.7497752 |  1.465439  | -0.6086780 |  3.9513610 | -0.7241274 | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  W1         W2        W3         A          Y         \n",
       "1  1.3357904 -1.214200  0.7023165  0.5581855  0.5296480\n",
       "2  0.5852906  1.040991 -0.7216398  0.6135768  0.5757955\n",
       "3  1.3420567 -1.848015 -1.0266263 -0.3826661 -0.3733951\n",
       "4  0.7343200 -1.726326 -0.5078887 -0.1823722 -0.1813630\n",
       "5 -0.1484268 -1.520334  1.2997251  0.3935576  0.3834764\n",
       "6  1.7497752  1.465439 -0.6086780  3.9513610 -0.7241274"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# simulate simple data for tmle-shift sketch\n",
    "W <- replicate(n_w, rnorm(n_obs))\n",
    "A <- rowSums(cos(exp(W)) + W)\n",
    "Y <- sin(A)\n",
    "O <- as.data.frame(cbind(W,A,Y))\n",
    "colnames(O) <- c(paste0(\"W\", seq_len(n_w)), \"A\", \"Y\")\n",
    "head(O)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bound_precision <- function(values_scaled) {\n",
    "    if (max(values_scaled) > 1 | min(values_scaled) < 0) {\n",
    "        stop(\"Scaled values are not in the interval [0, 1].\")\n",
    "    }\n",
    "    values_scaled[values_scaled == 0] <- .Machine$double.neg.eps\n",
    "    values_scaled[values_scaled == 1] <- 1 - .Machine$double.neg.eps\n",
    "    return(values_scaled)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "bound_scaling <- function(Y, preds_scaled = NULL,\n",
    "                          scale = c(\"zero_one\", \"original\")) {\n",
    "    y_min <- min(Y)\n",
    "    y_max <- max(Y)\n",
    "    \n",
    "    if (scale == \"zero_one\") {\n",
    "        y_star <- (Y - y_min) / (y_max - y_min)\n",
    "        return(y_star)\n",
    "    } else if (scale == \"original\" & !is.null(preds_scaled)) {\n",
    "        preds_original <- (y_max - y_min) * preds_scaled + y_min\n",
    "        return(preds_original)\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## functions for treatment shift $d(a,w)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tx_shift_g <- function(a, w = NULL, delta, type = \"additive\") {\n",
    "    if (type == \"additive\") {\n",
    "        a_shift <- A - delta\n",
    "    }\n",
    "    return(a_shift)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tx_shift_Q <- function(a, w = NULL, delta, type = \"additive\") {\n",
    "    if (type == \"additive\") {\n",
    "        a_shift <- A + delta\n",
    "    }\n",
    "    return(a_shift)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## function for estimating $g_n$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "est_g <- function(A, W, delta = 0, ...) {\n",
    "    # make data object\n",
    "    data_O <- as.data.frame(cbind(A, W))\n",
    "    colnames(data_O) <- c(\"A\", paste0(\"W\", seq_len(ncol(W))))\n",
    "    \n",
    "    # fit conditional density with condensier\n",
    "    fit_g_A <- fit_density(X = c(paste0(\"W\", seq_len(ncol(W)))),\n",
    "                           Y = \"A\", input_data = data_O, ...)\n",
    "\n",
    "    # predict probabilities for the un-shifted data (A = a)\n",
    "    pred_g_A <- predict_probability(model_fit = fit_g_A, newdata = data_O)\n",
    "\n",
    "    # predict probabilities for the shifted data (A = a - delta)\n",
    "    data_O_shifted <- data_O\n",
    "    data_O_shifted$A <- tx_shift_g(a = data_O_shifted$A, delta = delta)\n",
    "    pred_g_A_shifted <- predict_probability(model_fit = fit_g_A,\n",
    "                                            newdata = data_O_shifted)\n",
    "\n",
    "    # create output matrix: scenarios A = a, A = a - delta\n",
    "    out <- as.data.frame(cbind(pred_g_A, pred_g_A_shifted))\n",
    "    colnames(out) <- c(\"gn_unshifted\", \"gn_shifted\")\n",
    "    rownames(out) <- NULL\n",
    "    return(out)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "testing function for estimating $g_n$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_est_g <- est_g(A = A, W = W, delta = 0.5,\n",
    "                    nbins = 20, bin_method = \"equal.mass\",\n",
    "                    bin_estimator = speedglmR6$new())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>gn_unshifted</th><th scope=col>gn_shifted</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td> 2.6638932 </td><td>0.039036690</td></tr>\n",
       "\t<tr><td> 2.3326707 </td><td>0.013664372</td></tr>\n",
       "\t<tr><td> 0.2385218 </td><td>0.002145538</td></tr>\n",
       "\t<tr><td>10.7000630 </td><td>0.001911927</td></tr>\n",
       "\t<tr><td> 0.7127472 </td><td>0.020590110</td></tr>\n",
       "\t<tr><td> 0.5335457 </td><td>0.533545681</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ll}\n",
       " gn\\_unshifted & gn\\_shifted\\\\\n",
       "\\hline\n",
       "\t  2.6638932  & 0.039036690\\\\\n",
       "\t  2.3326707  & 0.013664372\\\\\n",
       "\t  0.2385218  & 0.002145538\\\\\n",
       "\t 10.7000630  & 0.001911927\\\\\n",
       "\t  0.7127472  & 0.020590110\\\\\n",
       "\t  0.5335457  & 0.533545681\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "gn_unshifted | gn_shifted | \n",
       "|---|---|---|---|---|---|\n",
       "|  2.6638932  | 0.039036690 | \n",
       "|  2.3326707  | 0.013664372 | \n",
       "|  0.2385218  | 0.002145538 | \n",
       "| 10.7000630  | 0.001911927 | \n",
       "|  0.7127472  | 0.020590110 | \n",
       "|  0.5335457  | 0.533545681 | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  gn_unshifted gn_shifted \n",
       "1  2.6638932   0.039036690\n",
       "2  2.3326707   0.013664372\n",
       "3  0.2385218   0.002145538\n",
       "4 10.7000630   0.001911927\n",
       "5  0.7127472   0.020590110\n",
       "6  0.5335457   0.533545681"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "head(test_est_g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## function for estimating $Q_n$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "est_Q <- function(Y, A, W, delta = 0, reg_form = \"Y ~ .\") {\n",
    "    # scale the outcome for the logit transform\n",
    "    y_star <- bound_scaling(Y = Y, scale = \"zero_one\")\n",
    "    \n",
    "    # make data object but using y_star rather than raw outcome\n",
    "    data_O <- as.data.frame(cbind(y_star, A, W))\n",
    "    colnames(data_O) <- c(\"Y\", \"A\", paste0(\"W\", seq_len(ncol(W))))\n",
    "    data_O_shifted <- data_O\n",
    "\n",
    "    # obtain a model fit for the outcome regression\n",
    "    fit_Qn <- glm(as.formula(reg_form), data = data_O)\n",
    "\n",
    "    # predict probabilities for the un-shifted data (A = a)\n",
    "    pred_star_Qn <- predict(fit_Qn, newdata = data_O)\n",
    "\n",
    "    # predict probabilities for the shifted data (A = a + delta)\n",
    "    data_O_shifted$A <- tx_shift_Q(a = data_O_shifted$A, delta = delta)\n",
    "    pred_star_Qn_shifted <- predict(fit_Qn, newdata = data_O_shifted)\n",
    "    \n",
    "    # avoid values that are exactly 0 or 1 in the scaled Qn and Qn_shifted\n",
    "    pred_star_Qn <- bound_precision(values_scaled = pred_star_Qn)\n",
    "    pred_star_Qn_shifted <- bound_precision(values_scaled = pred_star_Qn_shifted)\n",
    "\n",
    "    # create output matrix: scenarios A = a, A = a - delta\n",
    "    out <- as.data.frame(cbind(pred_star_Qn, pred_star_Qn_shifted))\n",
    "    colnames(out) <- c(\"Qn_unshifted\", \"Qn_shifted\")\n",
    "    rownames(out) <- NULL\n",
    "    return(out)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_est_Q <- est_Q(Y = Y, A = A, W = W, delta = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>Qn_unshifted</th><th scope=col>Qn_shifted</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>0.8140587</td><td>0.7936936</td></tr>\n",
       "\t<tr><td>0.6996480</td><td>0.6792830</td></tr>\n",
       "\t<tr><td>0.6275849</td><td>0.6072198</td></tr>\n",
       "\t<tr><td>0.6272340</td><td>0.6068689</td></tr>\n",
       "\t<tr><td>0.7341385</td><td>0.7137734</td></tr>\n",
       "\t<tr><td>0.7059962</td><td>0.6856311</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ll}\n",
       " Qn\\_unshifted & Qn\\_shifted\\\\\n",
       "\\hline\n",
       "\t 0.8140587 & 0.7936936\\\\\n",
       "\t 0.6996480 & 0.6792830\\\\\n",
       "\t 0.6275849 & 0.6072198\\\\\n",
       "\t 0.6272340 & 0.6068689\\\\\n",
       "\t 0.7341385 & 0.7137734\\\\\n",
       "\t 0.7059962 & 0.6856311\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "Qn_unshifted | Qn_shifted | \n",
       "|---|---|---|---|---|---|\n",
       "| 0.8140587 | 0.7936936 | \n",
       "| 0.6996480 | 0.6792830 | \n",
       "| 0.6275849 | 0.6072198 | \n",
       "| 0.6272340 | 0.6068689 | \n",
       "| 0.7341385 | 0.7137734 | \n",
       "| 0.7059962 | 0.6856311 | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  Qn_unshifted Qn_shifted\n",
       "1 0.8140587    0.7936936 \n",
       "2 0.6996480    0.6792830 \n",
       "3 0.6275849    0.6072198 \n",
       "4 0.6272340    0.6068689 \n",
       "5 0.7341385    0.7137734 \n",
       "6 0.7059962    0.6856311 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "head(test_est_Q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## function for estimating $H_n$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "est_h <- function(gn, a = NULL, w = NULL) {\n",
    "    # compute upper and lower limits for treatment\n",
    "    #...\n",
    "    #...\n",
    "    \n",
    "    # compute the ratio of the propensity scores\n",
    "    ratio_g <- gn[, 2] / gn[, 1]\n",
    "    \n",
    "    # modify the ratio of the propensity scores\n",
    "    # based on the indicators for shifting\n",
    "    #ind_a <- ...\n",
    "    #ind_a_delta <- ...\n",
    "    #h_n <- ind_a * ratio_g + ind_a_delta\n",
    "    \n",
    "    # TODO: consider case where there is not support everywhere\n",
    "    # that is, when the indicators kick in -- ignored for now...\n",
    "    hn <- ratio_g\n",
    "    \n",
    "    # output\n",
    "    return(hn)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_est_h <- est_h(gn = test_est_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>0.0146539997745853</li>\n",
       "\t<li>0.00585782285367919</li>\n",
       "\t<li>0.00899514384523805</li>\n",
       "\t<li>0.000178683750160215</li>\n",
       "\t<li>0.0288883773606865</li>\n",
       "\t<li>1</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 0.0146539997745853\n",
       "\\item 0.00585782285367919\n",
       "\\item 0.00899514384523805\n",
       "\\item 0.000178683750160215\n",
       "\\item 0.0288883773606865\n",
       "\\item 1\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 0.0146539997745853\n",
       "2. 0.00585782285367919\n",
       "3. 0.00899514384523805\n",
       "4. 0.000178683750160215\n",
       "5. 0.0288883773606865\n",
       "6. 1\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 0.0146539998 0.0058578229 0.0089951438 0.0001786838 0.0288883774\n",
       "[6] 1.0000000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "head(test_est_h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## function for fluctuation procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "est_fluc <- function(Y, Qn_scaled, Hn,\n",
    "                     method = c(\"standard\", \"weighted\")) {\n",
    "    # scale the outcome for the logit transform\n",
    "    y_star <- bound_scaling(Y = Y, scale = \"zero_one\")\n",
    "    \n",
    "    # transform the predictions for the unshifted data back to the original scale\n",
    "    Qn_star_unshifted <- bound_scaling(Y = Y, preds_scaled = Qn_scaled$Qn_unshifted,\n",
    "                                       scale = \"original\")\n",
    "    \n",
    "    # extract Q and obtain logit transform\n",
    "    logit_Qn <- qlogis(Qn_star_unshifted)\n",
    "    \n",
    "    # fit the fluctuation regression in one of two ways\n",
    "    if (method == \"standard\") {\n",
    "        # note that \\epsilon_n will be the coefficient of the covariate Hn\n",
    "        mod_fluc <- glm(y_star ~ -1 + offset(logit_Qn) + Hn,\n",
    "                        family = \"binomial\")\n",
    "    } else if (method == \"weighted\") {\n",
    "        # note that \\epsilon_n will be the intercept term here (?)\n",
    "        mod_fluc <- glm(y_star ~ offset(logit_Qn),\n",
    "                        weights = Hn,\n",
    "                        family = \"binomial\")\n",
    "    }\n",
    "   \n",
    "    # return the fit model object\n",
    "    out <- list(fluc_fit = mod_fluc, covar_method = method)\n",
    "    return(out)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-TMLE procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmle_shifttx <- function(fluc_fit, Qn, Hn, Y) {\n",
    "    # get Qn(d(A,W)) by unscaling the shifted Qn\n",
    "    Qn_shifted <- bound_scaling(Y = Y, preds_scaled = Qn_scaled$Qn_shifted,\n",
    "                                scale = \"original\")\n",
    "    \n",
    "    # get Qn_star for the shifted data\n",
    "    Qn_star_shifted <- predict(fit = fluc_fit, newdata = data.frame(Qn_shifted),\n",
    "                               type = \"response\")\n",
    "    \n",
    "    # compute the 1-TMLE\n",
    "    psi <- mean(Qn_star_shifted)\n",
    "    return(psi)   \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EIF procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eif_shifttx <- function(Y, Qn_scaled, Hn, Psi) {\n",
    "    # ...\n",
    "    Qn_unshifted <- bound_scaling(Y = Y, preds_scaled = Qn_scaled$Qn_unshifted,\n",
    "                                  scale = \"original\")\n",
    "    Qn_shifted <- bound_scaling(Y = Y, preds_scaled = Qn_scaled$Qn_shifted,\n",
    "                                scale = \"original\")\n",
    "    \n",
    "    # ...\n",
    "    eif <- Hn * (Y - Qn_unshifted) + Qn_shifted - Psi\n",
    "    \n",
    "    # compute the variance based on the EIF\n",
    "    var_eif <- mean(eif^2)\n",
    "    \n",
    "    # return the variance and the EIF vector\n",
    "    out <- list(var_psi = var_eif, eif = eif)\n",
    "    return(out)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anatomy of the shift-Tx package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The algorithm is based on @diaz2017stochastic.\n",
    "\n",
    "## Starting Assumptions\n",
    "\n",
    "1. Start with a simple additive shift -- i.e., $d(a,w) = a + \\delta$ if $a <\n",
    "    u(w) - \\delta$ or $d(a,w) = a$ if $a \\geq u(w) - \\delta$.\n",
    "2. The additive shift will have _support everywhere_ -- i.e., $a < u(w)$ is true\n",
    "    everywhere.\n",
    "3. The data structure that we know and love $O = (W,A,Y)$.\n",
    "\n",
    "## Functions Needed\n",
    "\n",
    "* estimate $g_n(W)$\n",
    "* estimate $Q_n(A, W)$\n",
    "* estimate auxiliary covariate $H_n(A_i, W_i)$\n",
    "* fluctuation procedure\n",
    "* 1-TMLE procedure\n",
    "* EIF procedure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimate $g_n(W)$\n",
    "\n",
    "* _input_: W, a\n",
    "* _output_: a 2-column matrix, with columns for $g_n(A_i - \\delta \\mid W_i)$ and\n",
    "    $g_n(A_i \\mid W_i)$\n",
    "* in the inputs $a$ is the additive shift\n",
    "* use the __fit_density__ function from Oleg's __condensier__ package, need to\n",
    "    use __predict_prob__ function twice: once for $A_i - \\delta$ and once for\n",
    "    $A_i$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimate $Q_n(A, W)$\n",
    "\n",
    "* _input_: W, a\n",
    "* _output_: a 2-column matrix, with columns for $\\bar{Q}_n(A_i, W_i)$ and\n",
    "    $\\bar{Q}_n(A_i + \\delta, W_i)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimate $H_n(A_i, W_i)$\n",
    "\n",
    "* _input_: matrix output produced by $g_n(w)$\n",
    "* _output_: vector (possibly shifted) of the form described in the eqn below\n",
    "* $H(a,w) = I(a < u(w)) \\frac{g_0(a - \\delta \\mid w)}{g_0(a \\mid w)} + I(a\n",
    "    \\geq u(w) - \\delta)$\n",
    "* By our assumption (2) above -- that we have _support everywhere_ -- we reduce\n",
    "    the above formulation\n",
    "* That is, we assume that $I(a < u(w)) = 1$ and $I(a \\geq u(w) - \\delta) = 0$\n",
    "* Thus the form of the covariate reduces simply to $H(a,w) = \\frac{g_0(a -\n",
    "    \\delta \\mid w)}{g_0(a \\mid w)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fluctuation Procedure\n",
    "\n",
    "* _input_: matrix output from $Q_n(a,w)$, vector output of $H_n$, vector Y\n",
    "* _output_: model fit object produced from a call to `glm` or `SuperLearner`\n",
    "* We have the fluctuation model: $logit \\bar{Q}_{\\epsilon, n}(a,w) =\n",
    "    logit(\\bar{Q}_n(a,w)) + \\epsilon \\cdot H_n(a,w)$\n",
    "* Note that the first term on the RHS of the above equation is one of the\n",
    "    columns generated as output by the function to estimate $Q_n(A,W)$\n",
    "* this could be fit with R code like the following `glm(Y ~ -1 +\n",
    "    offset(logitQn_AW) + Hn_AW, family = \"binomial\")`, from which we may extract\n",
    "    the coefficient, which is $\\epsilon_n$ from the above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-TMLE Procedure\n",
    "\n",
    "* _input_: model fit object produced by the fluctuation procedure above, matrix\n",
    "    produced by procedure to estimate $Q_n(A,W)$\n",
    "* _output_: numeric scalar for the mean of $\\bar{Q}^*_n$\n",
    "* note that we have $\\psi_n = \\frac{1}{n} \\sum_{i=1}^n \\bar{Q}_n^*(d(A_i, W_i),\n",
    "    W_i)$\n",
    "* we obtain $\\bar{Q}_n^*$ by calling the appropriate method of predict on the\n",
    "    shifted data -- i.e., `predict(fit, newdata = data.frame(Qn_dAW), type =\n",
    "    \"response\"` (note that use of 'response' performs the `expit()` transform).\n",
    "* compute the $\\psi_n$ as the mean of the vector produced by calling `predict`\n",
    "    on the fit object, as described above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EIF Procedure\n",
    "\n",
    "* _input_: matrix produced by $Q^*$: a 2-column matrix, with columns for\n",
    "    $\\bar{Q}_n(A_i, W_i)$ and $\\bar{Q}_n(A_i + \\delta, W_i)$\n",
    "* _output_: scalar, the variance of the efficient influence function\n",
    "* note that we have the _efficient influence function_ (EIF): $D(P)(o) =\n",
    "    H(a,w)(y - \\bar{Q}(a,w)) + \\bar{Q}(d(a,w)) - \\psi(P)$\n",
    "* to compute the EIF from the above, we may set up a function like the following\n",
    "    `eif <- function(Y, H, Qn_AW, Qn_dAW, Psi)`, which can then compute $\\psi$\n",
    "    by calling 1-TMLE (alternatively, the mean of the vector `Qn_dAW`) and then\n",
    "    using the formula above\n",
    "* compute $\\sigma^2_n = \\frac{1}{n}(EIF^2)$, that is simply call mean on the\n",
    "    vector produced by the above"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

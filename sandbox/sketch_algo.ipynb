{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing a new TMLE algorithm for a treatment shift parameter\n",
    "\n",
    "## adapted from \"Stochastic Treatment Regimes,\" in vdL+Rose, TL2 (forthcoming)\n",
    "\n",
    "### Authors: Nima Hejazi and David Benkeser\n",
    "\n",
    "### modified: 08 November 2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Starting Assumptions\n",
    "\n",
    "1. Start with a simple additive shift -- i.e., $d(a,w) = a + \\delta$ if $a <\n",
    "    u(w) - \\delta$ or $d(a,w) = a$ if $a \\geq u(w) - \\delta$.\n",
    "2. The additive shift will have _support everywhere_ -- i.e., $a < u(w)$ is true\n",
    "    everywhere.\n",
    "3. The data structure that we know and love $O = (W,A,Y)$.\n",
    "\n",
    "## Functions Needed\n",
    "\n",
    "* estimate $g_n(W)$\n",
    "* estimate $Q_n(A, W)$\n",
    "* estimate auxiliary covariate $H_n(A_i, W_i)$\n",
    "* fluctuation procedure\n",
    "* 1-TMLE procedure\n",
    "* EIF procedure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation of new shift-TMLE algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "condensier\n",
      "The condensier package is still in beta testing. Interpret results with caution.\n"
     ]
    }
   ],
   "source": [
    "library(sl3)\n",
    "library(condensier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rm(list = ls())\n",
    "set.seed(429153)\n",
    "n_obs <- 100\n",
    "n_w <- 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>W1</th><th scope=col>W2</th><th scope=col>W3</th><th scope=col>A</th><th scope=col>Y</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td> 1.3357904</td><td>-1.214200 </td><td> 0.7023165</td><td> 0.5581855</td><td> 0.5296480</td></tr>\n",
       "\t<tr><td> 0.5852906</td><td> 1.040991 </td><td>-0.7216398</td><td> 0.6135768</td><td> 0.5757955</td></tr>\n",
       "\t<tr><td> 1.3420567</td><td>-1.848015 </td><td>-1.0266263</td><td>-0.3826661</td><td>-0.3733951</td></tr>\n",
       "\t<tr><td> 0.7343200</td><td>-1.726326 </td><td>-0.5078887</td><td>-0.1823722</td><td>-0.1813630</td></tr>\n",
       "\t<tr><td>-0.1484268</td><td>-1.520334 </td><td> 1.2997251</td><td> 0.3935576</td><td> 0.3834764</td></tr>\n",
       "\t<tr><td> 1.7497752</td><td> 1.465439 </td><td>-0.6086780</td><td> 3.9513610</td><td>-0.7241274</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllll}\n",
       " W1 & W2 & W3 & A & Y\\\\\n",
       "\\hline\n",
       "\t  1.3357904 & -1.214200  &  0.7023165 &  0.5581855 &  0.5296480\\\\\n",
       "\t  0.5852906 &  1.040991  & -0.7216398 &  0.6135768 &  0.5757955\\\\\n",
       "\t  1.3420567 & -1.848015  & -1.0266263 & -0.3826661 & -0.3733951\\\\\n",
       "\t  0.7343200 & -1.726326  & -0.5078887 & -0.1823722 & -0.1813630\\\\\n",
       "\t -0.1484268 & -1.520334  &  1.2997251 &  0.3935576 &  0.3834764\\\\\n",
       "\t  1.7497752 &  1.465439  & -0.6086780 &  3.9513610 & -0.7241274\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "W1 | W2 | W3 | A | Y | \n",
       "|---|---|---|---|---|---|\n",
       "|  1.3357904 | -1.214200  |  0.7023165 |  0.5581855 |  0.5296480 | \n",
       "|  0.5852906 |  1.040991  | -0.7216398 |  0.6135768 |  0.5757955 | \n",
       "|  1.3420567 | -1.848015  | -1.0266263 | -0.3826661 | -0.3733951 | \n",
       "|  0.7343200 | -1.726326  | -0.5078887 | -0.1823722 | -0.1813630 | \n",
       "| -0.1484268 | -1.520334  |  1.2997251 |  0.3935576 |  0.3834764 | \n",
       "|  1.7497752 |  1.465439  | -0.6086780 |  3.9513610 | -0.7241274 | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  W1         W2        W3         A          Y         \n",
       "1  1.3357904 -1.214200  0.7023165  0.5581855  0.5296480\n",
       "2  0.5852906  1.040991 -0.7216398  0.6135768  0.5757955\n",
       "3  1.3420567 -1.848015 -1.0266263 -0.3826661 -0.3733951\n",
       "4  0.7343200 -1.726326 -0.5078887 -0.1823722 -0.1813630\n",
       "5 -0.1484268 -1.520334  1.2997251  0.3935576  0.3834764\n",
       "6  1.7497752  1.465439 -0.6086780  3.9513610 -0.7241274"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# simulate simple data for tmle-shift sketch\n",
    "W <- replicate(n_w, rnorm(n_obs))\n",
    "A <- rowSums(cos(exp(W)) + W)\n",
    "Y <- sin(A)\n",
    "O <- as.data.frame(cbind(W,A,Y))\n",
    "colnames(O) <- c(paste0(\"W\", seq_len(n_w)), \"A\", \"Y\")\n",
    "head(O)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bound_precision <- function(values_scaled) {\n",
    "    if (max(values_scaled) > 1 | min(values_scaled) < 0) {\n",
    "        stop(\"Scaled values are not in the interval [0, 1].\")\n",
    "    }\n",
    "    values_scaled[values_scaled == 0] <- .Machine$double.neg.eps\n",
    "    values_scaled[values_scaled == 1] <- 1 - .Machine$double.neg.eps\n",
    "    return(values_scaled)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bound_scaling <- function(Y, preds_scaled = NULL,\n",
    "                          scale = c(\"zero_one\", \"original\")) {\n",
    "    y_min <- min(Y)\n",
    "    y_max <- max(Y)\n",
    "    \n",
    "    if (scale == \"zero_one\") {\n",
    "        y_star <- (Y - y_min) / (y_max - y_min)\n",
    "        return(y_star)\n",
    "    } else if (scale == \"original\" & !is.null(preds_scaled)) {\n",
    "        preds_original <- (y_max - y_min) * preds_scaled + y_min\n",
    "        return(preds_original)\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using `sl3` for Super Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>'Lrnr_arima'</li>\n",
       "\t<li>'Lrnr_condensier'</li>\n",
       "\t<li>'Lrnr_expSmooth'</li>\n",
       "\t<li>'Lrnr_glm'</li>\n",
       "\t<li>'Lrnr_glm_fast'</li>\n",
       "\t<li>'Lrnr_glmnet'</li>\n",
       "\t<li>'Lrnr_h2o_glm'</li>\n",
       "\t<li>'Lrnr_h2o_grid'</li>\n",
       "\t<li>'Lrnr_HarmonicReg'</li>\n",
       "\t<li>'Lrnr_mean'</li>\n",
       "\t<li>'Lrnr_nnls'</li>\n",
       "\t<li>'Lrnr_optim'</li>\n",
       "\t<li>'Lrnr_pkg_SuperLearner'</li>\n",
       "\t<li>'Lrnr_pkg_SuperLearner_method'</li>\n",
       "\t<li>'Lrnr_pkg_SuperLearner_screener'</li>\n",
       "\t<li>'Lrnr_randomForest'</li>\n",
       "\t<li>'Lrnr_rugarch'</li>\n",
       "\t<li>'Lrnr_solnp'</li>\n",
       "\t<li>'Lrnr_tsDyn'</li>\n",
       "\t<li>'Lrnr_xgboost'</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'Lrnr\\_arima'\n",
       "\\item 'Lrnr\\_condensier'\n",
       "\\item 'Lrnr\\_expSmooth'\n",
       "\\item 'Lrnr\\_glm'\n",
       "\\item 'Lrnr\\_glm\\_fast'\n",
       "\\item 'Lrnr\\_glmnet'\n",
       "\\item 'Lrnr\\_h2o\\_glm'\n",
       "\\item 'Lrnr\\_h2o\\_grid'\n",
       "\\item 'Lrnr\\_HarmonicReg'\n",
       "\\item 'Lrnr\\_mean'\n",
       "\\item 'Lrnr\\_nnls'\n",
       "\\item 'Lrnr\\_optim'\n",
       "\\item 'Lrnr\\_pkg\\_SuperLearner'\n",
       "\\item 'Lrnr\\_pkg\\_SuperLearner\\_method'\n",
       "\\item 'Lrnr\\_pkg\\_SuperLearner\\_screener'\n",
       "\\item 'Lrnr\\_randomForest'\n",
       "\\item 'Lrnr\\_rugarch'\n",
       "\\item 'Lrnr\\_solnp'\n",
       "\\item 'Lrnr\\_tsDyn'\n",
       "\\item 'Lrnr\\_xgboost'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'Lrnr_arima'\n",
       "2. 'Lrnr_condensier'\n",
       "3. 'Lrnr_expSmooth'\n",
       "4. 'Lrnr_glm'\n",
       "5. 'Lrnr_glm_fast'\n",
       "6. 'Lrnr_glmnet'\n",
       "7. 'Lrnr_h2o_glm'\n",
       "8. 'Lrnr_h2o_grid'\n",
       "9. 'Lrnr_HarmonicReg'\n",
       "10. 'Lrnr_mean'\n",
       "11. 'Lrnr_nnls'\n",
       "12. 'Lrnr_optim'\n",
       "13. 'Lrnr_pkg_SuperLearner'\n",
       "14. 'Lrnr_pkg_SuperLearner_method'\n",
       "15. 'Lrnr_pkg_SuperLearner_screener'\n",
       "16. 'Lrnr_randomForest'\n",
       "17. 'Lrnr_rugarch'\n",
       "18. 'Lrnr_solnp'\n",
       "19. 'Lrnr_tsDyn'\n",
       "20. 'Lrnr_xgboost'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       " [1] \"Lrnr_arima\"                     \"Lrnr_condensier\"               \n",
       " [3] \"Lrnr_expSmooth\"                 \"Lrnr_glm\"                      \n",
       " [5] \"Lrnr_glm_fast\"                  \"Lrnr_glmnet\"                   \n",
       " [7] \"Lrnr_h2o_glm\"                   \"Lrnr_h2o_grid\"                 \n",
       " [9] \"Lrnr_HarmonicReg\"               \"Lrnr_mean\"                     \n",
       "[11] \"Lrnr_nnls\"                      \"Lrnr_optim\"                    \n",
       "[13] \"Lrnr_pkg_SuperLearner\"          \"Lrnr_pkg_SuperLearner_method\"  \n",
       "[15] \"Lrnr_pkg_SuperLearner_screener\" \"Lrnr_randomForest\"             \n",
       "[17] \"Lrnr_rugarch\"                   \"Lrnr_solnp\"                    \n",
       "[19] \"Lrnr_tsDyn\"                     \"Lrnr_xgboost\"                  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sl3_list_learners(c(\"continuous\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A sl3 Task with 100 observations and the following nodes:\n",
       "$covariates\n",
       "[1] \"A\"  \"W1\" \"W2\" \"W3\"\n",
       "\n",
       "$outcome\n",
       "[1] \"Y\"\n",
       "\n",
       "$id\n",
       "NULL\n",
       "\n",
       "$weights\n",
       "NULL\n",
       "\n",
       "$offset\n",
       "NULL\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create sl3 task from the input data\n",
    "task <- make_sl3_Task(data = O, covariates = c(\"A\", paste0(\"W\", seq_len(n_w))),\n",
    "                      outcome = \"Y\", outcome_type = \"continuous\")\n",
    "task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create learners and set up a stack\n",
    "lrnr_mean <- make_learner(Lrnr_mean)\n",
    "lrnr_glm_fast <- make_learner(Lrnr_glm_fast)\n",
    "lrnr_xgboost <- make_learner(Lrnr_xgboost)\n",
    "stack <- make_learner(Stack, lrnr_mean, lrnr_glm_fast, lrnr_xgboost)\n",
    "\n",
    "# use the NNLS meta-learner\n",
    "metalearner <- make_learner(Lrnr_nnls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fit_sl <- function(learners_stack, metalearner) {\n",
    "    sl <- Lrnr_sl$new(learners = stack,\n",
    "                      metalearner = metalearner)\n",
    "    sl_fit <- sl$train(task)\n",
    "    lrnr_sl_preds <- sl_fit$predict() \n",
    "    return(lrnr_sl_preds)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## functions for treatment shift $d(a,w)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "tx_shift <- function(a, w = NULL, delta, type = \"additive\",\n",
    "                     reg = c(\"g\", \"Q\")) {\n",
    "    if (type == \"additive\") {\n",
    "        if (reg == \"g\") {\n",
    "            a_shift <- A - delta\n",
    "        }\n",
    "        if (reg == \"Q\") {\n",
    "            a_shift <- A + delta\n",
    "        }\n",
    "    }\n",
    "    # can support other types of treatment shifts\n",
    "    # (e.g., multiplicative shifting?)\n",
    "    return(a_shift)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimate propensity score $g_n(W)$\n",
    "\n",
    "* _input_: W, a\n",
    "* _output_: a 2-column matrix, with columns for $g_n(A_i - \\delta \\mid W_i)$ and\n",
    "    $g_n(A_i \\mid W_i)$\n",
    "* in the inputs $a$ is the additive shift\n",
    "* use the __fit_density__ function from Oleg's __condensier__ package, need to\n",
    "    use __predict_prob__ function twice: once for $A_i - \\delta$ and once for\n",
    "    $A_i$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## function for estimating $g_n$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "est_g <- function(A, W, delta = 0, ...) {\n",
    "    # make data object\n",
    "    data_O <- as.data.frame(cbind(A, W))\n",
    "    colnames(data_O) <- c(\"A\", paste0(\"W\", seq_len(ncol(W))))\n",
    "    \n",
    "    # fit conditional density with condensier\n",
    "    fit_g_A <- fit_density(X = c(paste0(\"W\", seq_len(ncol(W)))),\n",
    "                           Y = \"A\", input_data = data_O, ...)\n",
    "\n",
    "    # predict probabilities for the un-shifted data (A = a)\n",
    "    pred_g_A <- predict_probability(model_fit = fit_g_A, newdata = data_O)\n",
    "\n",
    "    # predict probabilities for the shifted data (A = a - delta)\n",
    "    data_O_shifted <- data_O\n",
    "    data_O_shifted$A <- tx_shift(a = data_O_shifted$A, delta = delta,\n",
    "                                 type = \"additive\", reg = \"g\")\n",
    "    pred_g_A_shifted <- predict_probability(model_fit = fit_g_A,\n",
    "                                            newdata = data_O_shifted)\n",
    "\n",
    "    # create output matrix: scenarios A = a, A = a - delta\n",
    "    out <- as.data.frame(cbind(pred_g_A, pred_g_A_shifted))\n",
    "    colnames(out) <- c(\"gn_unshifted\", \"gn_shifted\")\n",
    "    rownames(out) <- NULL\n",
    "    return(out)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "testing function for estimating $g_n$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_est_g <- est_g(A = A,\n",
    "                    W = W,\n",
    "                    delta = 0.5,\n",
    "                    nbins = 20,\n",
    "                    bin_method = \"equal.mass\",\n",
    "                    bin_estimator = speedglmR6$new())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>gn_unshifted</th><th scope=col>gn_shifted</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td> 2.6638932 </td><td>0.039036690</td></tr>\n",
       "\t<tr><td> 2.3326707 </td><td>0.013664372</td></tr>\n",
       "\t<tr><td> 0.2385218 </td><td>0.002145538</td></tr>\n",
       "\t<tr><td>10.7000630 </td><td>0.001911927</td></tr>\n",
       "\t<tr><td> 0.7127472 </td><td>0.020590110</td></tr>\n",
       "\t<tr><td> 0.5335457 </td><td>0.533545681</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ll}\n",
       " gn\\_unshifted & gn\\_shifted\\\\\n",
       "\\hline\n",
       "\t  2.6638932  & 0.039036690\\\\\n",
       "\t  2.3326707  & 0.013664372\\\\\n",
       "\t  0.2385218  & 0.002145538\\\\\n",
       "\t 10.7000630  & 0.001911927\\\\\n",
       "\t  0.7127472  & 0.020590110\\\\\n",
       "\t  0.5335457  & 0.533545681\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "gn_unshifted | gn_shifted | \n",
       "|---|---|---|---|---|---|\n",
       "|  2.6638932  | 0.039036690 | \n",
       "|  2.3326707  | 0.013664372 | \n",
       "|  0.2385218  | 0.002145538 | \n",
       "| 10.7000630  | 0.001911927 | \n",
       "|  0.7127472  | 0.020590110 | \n",
       "|  0.5335457  | 0.533545681 | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  gn_unshifted gn_shifted \n",
       "1  2.6638932   0.039036690\n",
       "2  2.3326707   0.013664372\n",
       "3  0.2385218   0.002145538\n",
       "4 10.7000630   0.001911927\n",
       "5  0.7127472   0.020590110\n",
       "6  0.5335457   0.533545681"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "head(test_est_g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimate outcome regression $Q_n(A, W)$\n",
    "\n",
    "* _input_: W, a\n",
    "* _output_: a 2-column matrix, with columns for $\\bar{Q}_n(A_i, W_i)$ and\n",
    "    $\\bar{Q}_n(A_i + \\delta, W_i)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## function for estimating $Q_n$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "est_Q <- function(Y, A, W, delta = 0, glm_form = \"Y ~ .\",\n",
    "                  sl_lrnrs = NULL, sl_meta = NULL) {\n",
    "    # scale the outcome for the logit transform\n",
    "    y_star <- bound_scaling(Y = Y, scale = \"zero_one\")\n",
    "    \n",
    "    # make data object but using y_star rather than raw outcome\n",
    "    data_O <- as.data.frame(cbind(y_star, A, W))\n",
    "    colnames(data_O) <- c(\"Y\", \"A\", paste0(\"W\", seq_len(ncol(W))))\n",
    "    \n",
    "    # get the shifted treatment values\n",
    "    a_shifted <- tx_shift(a = data_O$A, delta = delta,\n",
    "                          type = \"additive\", reg = \"Q\")\n",
    "    \n",
    "    # create a copy of the data for the shifted data set\n",
    "    # and replace A with the shifted treatment (A = a + delta)\n",
    "    data_O_shifted <- data_O\n",
    "    data_O_shifted$A <- a_shifted\n",
    "\n",
    "    if (!is.null(glm_form)) {\n",
    "        # obtain a GLM model fit for the outcome regression\n",
    "        fit_Qn <- glm(as.formula(glm_form), data = data_O)\n",
    "        \n",
    "        # predict Qn for the un-shifted data (A = a)\n",
    "        pred_star_Qn <- predict(fit_Qn, newdata = data_O)\n",
    "        \n",
    "        # predict Qn for the shifted data (A = a + delta)\n",
    "        pred_star_Qn_shifted <- predict(fit_Qn, newdata = data_O_shifted)\n",
    "    }\n",
    "    \n",
    "    if (!is.null(sl_lrnrs) & !is.null(sl_meta)) {\n",
    "        # make sl3 task for original data\n",
    "        task_noshift <- make_sl3_Task(data = data_O,\n",
    "                                      covariates = c(\"A\", paste0(\"W\", seq_len(n_w))),\n",
    "                                      outcome = \"Y\", outcome_type = \"continuous\")\n",
    "\n",
    "        # make sl3 task for data with the shifted treatment\n",
    "        task_shifted <- make_sl3_Task(data = data_O_shifted,\n",
    "                                      covariates = c(\"A\", paste0(\"W\", seq_len(n_w))),\n",
    "                                      outcome = \"Y\", outcome_type = \"continuous\")\n",
    "        # fit SL\n",
    "    }\n",
    "\n",
    "    # avoid values that are exactly 0 or 1 in the scaled Qn and Qn_shifted\n",
    "    pred_star_Qn <- bound_precision(values_scaled = pred_star_Qn)\n",
    "    pred_star_Qn_shifted <- bound_precision(values_scaled = pred_star_Qn_shifted)\n",
    "\n",
    "    # create output matrix: scenarios A = a, A = a - delta\n",
    "    out <- as.data.frame(cbind(pred_star_Qn, pred_star_Qn_shifted))\n",
    "    colnames(out) <- c(\"Qn_unshifted\", \"Qn_shifted\")\n",
    "    rownames(out) <- NULL\n",
    "    return(out)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_est_Q <- est_Q(Y = Y,\n",
    "                    A = A,\n",
    "                    W = W,\n",
    "                    delta = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>Qn_unshifted</th><th scope=col>Qn_shifted</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>0.8140587</td><td>0.7936936</td></tr>\n",
       "\t<tr><td>0.6996480</td><td>0.6792830</td></tr>\n",
       "\t<tr><td>0.6275849</td><td>0.6072198</td></tr>\n",
       "\t<tr><td>0.6272340</td><td>0.6068689</td></tr>\n",
       "\t<tr><td>0.7341385</td><td>0.7137734</td></tr>\n",
       "\t<tr><td>0.7059962</td><td>0.6856311</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ll}\n",
       " Qn\\_unshifted & Qn\\_shifted\\\\\n",
       "\\hline\n",
       "\t 0.8140587 & 0.7936936\\\\\n",
       "\t 0.6996480 & 0.6792830\\\\\n",
       "\t 0.6275849 & 0.6072198\\\\\n",
       "\t 0.6272340 & 0.6068689\\\\\n",
       "\t 0.7341385 & 0.7137734\\\\\n",
       "\t 0.7059962 & 0.6856311\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "Qn_unshifted | Qn_shifted | \n",
       "|---|---|---|---|---|---|\n",
       "| 0.8140587 | 0.7936936 | \n",
       "| 0.6996480 | 0.6792830 | \n",
       "| 0.6275849 | 0.6072198 | \n",
       "| 0.6272340 | 0.6068689 | \n",
       "| 0.7341385 | 0.7137734 | \n",
       "| 0.7059962 | 0.6856311 | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  Qn_unshifted Qn_shifted\n",
       "1 0.8140587    0.7936936 \n",
       "2 0.6996480    0.6792830 \n",
       "3 0.6275849    0.6072198 \n",
       "4 0.6272340    0.6068689 \n",
       "5 0.7341385    0.7137734 \n",
       "6 0.7059962    0.6856311 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "head(test_est_Q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimate auxiliary covariate $H_n(A_i, W_i)$\n",
    "\n",
    "* _input_: matrix output produced by $g_n(w)$\n",
    "* _output_: vector (possibly shifted) of the form described in the eqn below\n",
    "* $H(a,w) = I(a < u(w)) \\frac{g_0(a - \\delta \\mid w)}{g_0(a \\mid w)} + I(a\n",
    "    \\geq u(w) - \\delta)$\n",
    "* By our assumption (2) above -- that we have _support everywhere_ -- we reduce\n",
    "    the above formulation\n",
    "* That is, we assume that $I(a < u(w)) = 1$ and $I(a \\geq u(w) - \\delta) = 0$\n",
    "* Thus the form of the covariate reduces simply to $H(a,w) = \\frac{g_0(a -\n",
    "    \\delta \\mid w)}{g_0(a \\mid w)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## function for estimating $H_n$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "est_h <- function(gn, a = NULL, w = NULL) {\n",
    "    # compute upper and lower limits for treatment\n",
    "    #...\n",
    "    #...\n",
    "    \n",
    "    # compute the ratio of the propensity scores\n",
    "    ratio_g <- gn[, 2] / gn[, 1]\n",
    "    \n",
    "    # modify the ratio of the propensity scores\n",
    "    # based on the indicators for shifting\n",
    "    #ind_a <- ...\n",
    "    #ind_a_delta <- ...\n",
    "    #h_n <- ind_a * ratio_g + ind_a_delta\n",
    "    \n",
    "    # TODO: consider case where there is not support everywhere\n",
    "    # that is, when the indicators kick in -- ignored for now...\n",
    "    hn <- ratio_g + 1\n",
    "    \n",
    "    # output\n",
    "    return(hn)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_est_h <- est_h(gn = test_est_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>1.01465399977459</li>\n",
       "\t<li>1.00585782285368</li>\n",
       "\t<li>1.00899514384524</li>\n",
       "\t<li>1.00017868375016</li>\n",
       "\t<li>1.02888837736069</li>\n",
       "\t<li>2</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 1.01465399977459\n",
       "\\item 1.00585782285368\n",
       "\\item 1.00899514384524\n",
       "\\item 1.00017868375016\n",
       "\\item 1.02888837736069\n",
       "\\item 2\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 1.01465399977459\n",
       "2. 1.00585782285368\n",
       "3. 1.00899514384524\n",
       "4. 1.00017868375016\n",
       "5. 1.02888837736069\n",
       "6. 2\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 1.014654 1.005858 1.008995 1.000179 1.028888 2.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "head(test_est_h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fluctuation Procedure\n",
    "\n",
    "* _input_: matrix output from $Q_n(a,w)$, vector output of $H_n$, vector Y\n",
    "* _output_: model fit object produced from a call to `glm` or `SuperLearner`\n",
    "* We have the fluctuation model: $logit \\bar{Q}_{\\epsilon, n}(a,w) =\n",
    "    logit(\\bar{Q}_n(a,w)) + \\epsilon \\cdot H_n(a,w)$\n",
    "* Note that the first term on the RHS of the above equation is one of the\n",
    "    columns generated as output by the function to estimate $Q_n(A,W)$\n",
    "* this could be fit with R code like the following `glm(Y ~ -1 +\n",
    "    offset(logitQn_AW) + Hn_AW, family = \"binomial\")`, from which we may extract\n",
    "    the coefficient, which is $\\epsilon_n$ from the above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## function for fluctuation procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "est_fluc <- function(Y, Qn_scaled, Hn,\n",
    "                     method = c(\"standard\", \"weighted\")) {\n",
    "    # scale the outcome for the logit transform\n",
    "    y_star <- bound_scaling(Y = Y, scale = \"zero_one\")\n",
    "    \n",
    "    # transform the predictions for the unshifted data back to the original scale\n",
    "    Qn_star_unshifted <- bound_scaling(Y = Y, preds_scaled = Qn_scaled$Qn_unshifted,\n",
    "                                       scale = \"original\")\n",
    "    \n",
    "    # extract Q and obtain logit transform\n",
    "    logit_Qn <- qlogis(Qn_star_unshifted)\n",
    "    \n",
    "    # fit the fluctuation regression in one of two ways\n",
    "    if (method == \"standard\") {\n",
    "        # note that \\epsilon_n will be the coefficient of the covariate Hn\n",
    "        mod_fluc <- glm(y_star ~ -1 + offset(logit_Qn) + Hn,\n",
    "                        family = \"binomial\")\n",
    "    } else if (method == \"weighted\") {\n",
    "        # note that \\epsilon_n will be the intercept term here (?)\n",
    "        mod_fluc <- glm(y_star ~ logit_Qn,\n",
    "                        weights = Hn,\n",
    "                        family = \"binomial\")\n",
    "    }\n",
    "   \n",
    "    # return the fit model object\n",
    "    out <- list(fluc_fit = mod_fluc, covar_method = method)\n",
    "    return(out)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in qlogis(Qn_star_unshifted):\n",
      "“NaNs produced”Warning message in eval(family$initialize):\n",
      "“non-integer #successes in a binomial glm!”"
     ]
    }
   ],
   "source": [
    "test_est_fluc1 <- est_fluc(Y = Y,\n",
    "                          Qn_scaled = test_est_Q,\n",
    "                          Hn = test_est_h,\n",
    "                          method = \"standard\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "$fluc_fit\n",
       "\n",
       "Call:  glm(formula = y_star ~ -1 + offset(logit_Qn) + Hn, family = \"binomial\")\n",
       "\n",
       "Coefficients:\n",
       "   Hn  \n",
       "1.123  \n",
       "\n",
       "Degrees of Freedom: 90 Total (i.e. Null);  89 Residual\n",
       "  (10 observations deleted due to missingness)\n",
       "Null Deviance:\t    95.41 \n",
       "Residual Deviance: 41.64 \tAIC: 106.4\n",
       "\n",
       "$covar_method\n",
       "[1] \"standard\"\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_est_fluc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in qlogis(Qn_star_unshifted):\n",
      "“NaNs produced”Warning message in eval(family$initialize):\n",
      "“non-integer #successes in a binomial glm!”"
     ]
    }
   ],
   "source": [
    "test_est_fluc2 <- est_fluc(Y = Y,\n",
    "                          Qn_scaled = test_est_Q,\n",
    "                          Hn = test_est_h,\n",
    "                          method = \"weighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "$fluc_fit\n",
       "\n",
       "Call:  glm(formula = y_star ~ logit_Qn, family = \"binomial\", weights = Hn)\n",
       "\n",
       "Coefficients:\n",
       "(Intercept)     logit_Qn  \n",
       "     1.2327       0.2785  \n",
       "\n",
       "Degrees of Freedom: 89 Total (i.e. Null);  88 Residual\n",
       "  (10 observations deleted due to missingness)\n",
       "Null Deviance:\t    60.55 \n",
       "Residual Deviance: 57.06 \tAIC: 143.2\n",
       "\n",
       "$covar_method\n",
       "[1] \"weighted\"\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_est_fluc2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1-TMLE Procedure\n",
    "\n",
    "* _input_: model fit object produced by the fluctuation procedure above, matrix\n",
    "    produced by procedure to estimate $Q_n(A,W)$\n",
    "* _output_: numeric scalar for the mean of $\\bar{Q}^*_n$\n",
    "* note that we have $\\psi_n = \\frac{1}{n} \\sum_{i=1}^n \\bar{Q}_n^*(d(A_i, W_i),\n",
    "    W_i)$\n",
    "* we obtain $\\bar{Q}_n^*$ by calling the appropriate method of predict on the\n",
    "    shifted data -- i.e., `predict(fit, newdata = data.frame(Qn_dAW), type =\n",
    "    \"response\"` (note that use of 'response' performs the `expit()` transform).\n",
    "* compute the $\\psi_n$ as the mean of the vector produced by calling `predict`\n",
    "    on the fit object, as described above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## function for the 1-TMLE procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmle_shifttx <- function(fluc_fit, Qn_scaled, Hn, Y) {\n",
    "    # get Qn(d(A,W)) by unscaling the shifted Qn\n",
    "    Qn_shifted <- bound_scaling(Y = Y, preds_scaled = Qn_scaled$Qn_shifted,\n",
    "                                scale = \"original\")\n",
    "    Qn_shifted <- as.data.frame(Qn_shifted)\n",
    "    \n",
    "    # HACK: looks like newdata has to have the same name as terms in the\n",
    "    # previously fit GLM model fit object\n",
    "    colnames(Qn_shifted) <- \"logit_Qn\"\n",
    "    \n",
    "    # get Qn_star for the shifted data\n",
    "    Qn_star_shifted <- predict(object = fluc_fit, newdata = Qn_shifted,\n",
    "                               type = \"response\")\n",
    "    \n",
    "    # compute the 1-TMLE\n",
    "    psi <- mean(Qn_star_shifted)\n",
    "    return(psi)   \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "est_tmle <- tmle_shifttx(fluc_fit = test_est_fluc1$fluc_fit,\n",
    "                         Qn_scaled = test_est_Q,\n",
    "                         Hn = test_est_h,\n",
    "                         Y = Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.861322151228436"
      ],
      "text/latex": [
       "0.861322151228436"
      ],
      "text/markdown": [
       "0.861322151228436"
      ],
      "text/plain": [
       "[1] 0.8613222"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "est_tmle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EIF Procedure\n",
    "\n",
    "* _input_: matrix produced by $Q^*$: a 2-column matrix, with columns for\n",
    "    $\\bar{Q}_n(A_i, W_i)$ and $\\bar{Q}_n(A_i + \\delta, W_i)$\n",
    "* _output_: scalar, the variance of the efficient influence function\n",
    "* note that we have the _efficient influence function_ (EIF): $D(P)(o) =\n",
    "    H(a,w)(y - \\bar{Q}(a,w)) + \\bar{Q}(d(a,w)) - \\psi(P)$\n",
    "* to compute the EIF from the above, we may set up a function like the following\n",
    "    `eif <- function(Y, H, Qn_AW, Qn_dAW, Psi)`, which can then compute $\\psi$\n",
    "    by calling 1-TMLE (alternatively, the mean of the vector `Qn_dAW`) and then\n",
    "    using the formula above\n",
    "* compute $\\sigma^2_n = \\frac{1}{n}(EIF^2)$, that is simply call mean on the\n",
    "    vector produced by the above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## function for the EIF procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eif_shifttx <- function(Y, Qn_scaled, Hn, Psi) {\n",
    "    # transform Qn based on shifted and unshifted treatments back to the...\n",
    "    # original outcome scale\n",
    "    Qn_unshifted <- bound_scaling(Y = Y, preds_scaled = Qn_scaled$Qn_unshifted,\n",
    "                                  scale = \"original\")\n",
    "    Qn_shifted <- bound_scaling(Y = Y, preds_scaled = Qn_scaled$Qn_shifted,\n",
    "                                scale = \"original\")\n",
    "    \n",
    "    # compute the efficient influence function (canonical gradient)\n",
    "    eif <- Hn * (Y - Qn_unshifted) + Qn_shifted - Psi\n",
    "    \n",
    "    # compute the variance based on the EIF\n",
    "    var_eif <- mean(eif^2)\n",
    "    \n",
    "    # return the variance and the EIF value at each observation\n",
    "    out <- list(var_psi = var_eif, eif = eif)\n",
    "    return(out)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_eif <- eif_shifttx(Y = Y,\n",
    "                        Qn_scaled = test_est_Q,\n",
    "                        Hn = test_est_h,\n",
    "                        Psi = est_tmle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<dl>\n",
       "\t<dt>$var_psi</dt>\n",
       "\t\t<dd>1.83281839903412</dd>\n",
       "\t<dt>$eif</dt>\n",
       "\t\t<dd><ol class=list-inline>\n",
       "\t<li>-0.372921672333097</li>\n",
       "\t<li>-0.324246625667895</li>\n",
       "\t<li>-1.28020859945993</li>\n",
       "\t<li>-1.08242807340988</li>\n",
       "\t<li>-0.520360059564868</li>\n",
       "\t<li>-2.77665824412097</li>\n",
       "\t<li>-1.75785937824695</li>\n",
       "\t<li>-0.0115865998942425</li>\n",
       "\t<li>-0.760688501674998</li>\n",
       "\t<li>-0.224745975492653</li>\n",
       "\t<li>0.133691894334689</li>\n",
       "\t<li>-0.0623175879709293</li>\n",
       "\t<li>0.389167783339204</li>\n",
       "\t<li>-2.91221854410309</li>\n",
       "\t<li>0.446712381668319</li>\n",
       "\t<li>-1.07427380676657</li>\n",
       "\t<li>-0.372751905140712</li>\n",
       "\t<li>-1.83872678581402</li>\n",
       "\t<li>-1.1622951806231</li>\n",
       "\t<li>-1.13666963744829</li>\n",
       "\t<li>-0.738524854032173</li>\n",
       "\t<li>-1.09175369708268</li>\n",
       "\t<li>-1.26358833443541</li>\n",
       "\t<li>-0.481364643303497</li>\n",
       "\t<li>-0.765373194237957</li>\n",
       "\t<li>0.125872872997511</li>\n",
       "\t<li>-1.02778607325117</li>\n",
       "\t<li>-1.05474823702699</li>\n",
       "\t<li>0.178263120666102</li>\n",
       "\t<li>-0.619411474579546</li>\n",
       "\t<li>-1.19539393710001</li>\n",
       "\t<li>-0.237266744179227</li>\n",
       "\t<li>1.35766527807544</li>\n",
       "\t<li>-0.590458673588672</li>\n",
       "\t<li>0.291732801416383</li>\n",
       "\t<li>-1.39501771150311</li>\n",
       "\t<li>-0.354542849901276</li>\n",
       "\t<li>1.31060949798089</li>\n",
       "\t<li>0.495487308188853</li>\n",
       "\t<li>0.503588861221951</li>\n",
       "\t<li>-0.127013241299687</li>\n",
       "\t<li>-1.10928001105542</li>\n",
       "\t<li>-0.249993738992425</li>\n",
       "\t<li>1.23952948017547</li>\n",
       "\t<li>-0.052395330570277</li>\n",
       "\t<li>-0.632121997452193</li>\n",
       "\t<li>-1.2595674135327</li>\n",
       "\t<li>0.115442430164227</li>\n",
       "\t<li>-0.106972147067973</li>\n",
       "\t<li>0.235607376354369</li>\n",
       "\t<li>0.992333486527257</li>\n",
       "\t<li>-0.797813209116758</li>\n",
       "\t<li>-1.99097464131076</li>\n",
       "\t<li>-1.51724874785765</li>\n",
       "\t<li>-0.624477815864842</li>\n",
       "\t<li>-2.37933610989996</li>\n",
       "\t<li>-1.16967882788794</li>\n",
       "\t<li>-1.84851082648874</li>\n",
       "\t<li>-0.886500417835579</li>\n",
       "\t<li>-0.794945073127971</li>\n",
       "\t<li>0.152665131597709</li>\n",
       "\t<li>-2.61889443585171</li>\n",
       "\t<li>-0.38217018238659</li>\n",
       "\t<li>-1.05806161263887</li>\n",
       "\t<li>-0.0682956914372747</li>\n",
       "\t<li>-1.0078467754996</li>\n",
       "\t<li>0.036664614482167</li>\n",
       "\t<li>-0.435516332764412</li>\n",
       "\t<li>0.0704412486361709</li>\n",
       "\t<li>0.181877174720244</li>\n",
       "\t<li>0.717919545666127</li>\n",
       "\t<li>0.505658881687694</li>\n",
       "\t<li>0.336839655356745</li>\n",
       "\t<li>-0.858566614804691</li>\n",
       "\t<li>-2.19770019207986</li>\n",
       "\t<li>-2.64719713010457</li>\n",
       "\t<li>-0.866135315020671</li>\n",
       "\t<li>-1.4592874153835</li>\n",
       "\t<li>0.767757555221814</li>\n",
       "\t<li>-0.986174169958301</li>\n",
       "\t<li>0.372397762236261</li>\n",
       "\t<li>-0.250976655578385</li>\n",
       "\t<li>0.281714836334476</li>\n",
       "\t<li>0.0359571075030972</li>\n",
       "\t<li>-0.851039274099525</li>\n",
       "\t<li>-0.0130256385186874</li>\n",
       "\t<li>-0.0900046351697245</li>\n",
       "\t<li>-2.75816247166997</li>\n",
       "\t<li>-0.324123962254866</li>\n",
       "\t<li>-0.492588302939271</li>\n",
       "\t<li>0.324308230052107</li>\n",
       "\t<li>-0.291464411643121</li>\n",
       "\t<li>-1.1691381575818</li>\n",
       "\t<li>8.49776941149641</li>\n",
       "\t<li>-1.49842683067686</li>\n",
       "\t<li>-0.388859260082862</li>\n",
       "\t<li>0.214556943753397</li>\n",
       "\t<li>0.090958013078656</li>\n",
       "\t<li>0.0659576362537988</li>\n",
       "\t<li>0.0753863540885256</li>\n",
       "</ol>\n",
       "</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description}\n",
       "\\item[\\$var\\_psi] 1.83281839903412\n",
       "\\item[\\$eif] \\begin{enumerate*}\n",
       "\\item -0.372921672333097\n",
       "\\item -0.324246625667895\n",
       "\\item -1.28020859945993\n",
       "\\item -1.08242807340988\n",
       "\\item -0.520360059564868\n",
       "\\item -2.77665824412097\n",
       "\\item -1.75785937824695\n",
       "\\item -0.0115865998942425\n",
       "\\item -0.760688501674998\n",
       "\\item -0.224745975492653\n",
       "\\item 0.133691894334689\n",
       "\\item -0.0623175879709293\n",
       "\\item 0.389167783339204\n",
       "\\item -2.91221854410309\n",
       "\\item 0.446712381668319\n",
       "\\item -1.07427380676657\n",
       "\\item -0.372751905140712\n",
       "\\item -1.83872678581402\n",
       "\\item -1.1622951806231\n",
       "\\item -1.13666963744829\n",
       "\\item -0.738524854032173\n",
       "\\item -1.09175369708268\n",
       "\\item -1.26358833443541\n",
       "\\item -0.481364643303497\n",
       "\\item -0.765373194237957\n",
       "\\item 0.125872872997511\n",
       "\\item -1.02778607325117\n",
       "\\item -1.05474823702699\n",
       "\\item 0.178263120666102\n",
       "\\item -0.619411474579546\n",
       "\\item -1.19539393710001\n",
       "\\item -0.237266744179227\n",
       "\\item 1.35766527807544\n",
       "\\item -0.590458673588672\n",
       "\\item 0.291732801416383\n",
       "\\item -1.39501771150311\n",
       "\\item -0.354542849901276\n",
       "\\item 1.31060949798089\n",
       "\\item 0.495487308188853\n",
       "\\item 0.503588861221951\n",
       "\\item -0.127013241299687\n",
       "\\item -1.10928001105542\n",
       "\\item -0.249993738992425\n",
       "\\item 1.23952948017547\n",
       "\\item -0.052395330570277\n",
       "\\item -0.632121997452193\n",
       "\\item -1.2595674135327\n",
       "\\item 0.115442430164227\n",
       "\\item -0.106972147067973\n",
       "\\item 0.235607376354369\n",
       "\\item 0.992333486527257\n",
       "\\item -0.797813209116758\n",
       "\\item -1.99097464131076\n",
       "\\item -1.51724874785765\n",
       "\\item -0.624477815864842\n",
       "\\item -2.37933610989996\n",
       "\\item -1.16967882788794\n",
       "\\item -1.84851082648874\n",
       "\\item -0.886500417835579\n",
       "\\item -0.794945073127971\n",
       "\\item 0.152665131597709\n",
       "\\item -2.61889443585171\n",
       "\\item -0.38217018238659\n",
       "\\item -1.05806161263887\n",
       "\\item -0.0682956914372747\n",
       "\\item -1.0078467754996\n",
       "\\item 0.036664614482167\n",
       "\\item -0.435516332764412\n",
       "\\item 0.0704412486361709\n",
       "\\item 0.181877174720244\n",
       "\\item 0.717919545666127\n",
       "\\item 0.505658881687694\n",
       "\\item 0.336839655356745\n",
       "\\item -0.858566614804691\n",
       "\\item -2.19770019207986\n",
       "\\item -2.64719713010457\n",
       "\\item -0.866135315020671\n",
       "\\item -1.4592874153835\n",
       "\\item 0.767757555221814\n",
       "\\item -0.986174169958301\n",
       "\\item 0.372397762236261\n",
       "\\item -0.250976655578385\n",
       "\\item 0.281714836334476\n",
       "\\item 0.0359571075030972\n",
       "\\item -0.851039274099525\n",
       "\\item -0.0130256385186874\n",
       "\\item -0.0900046351697245\n",
       "\\item -2.75816247166997\n",
       "\\item -0.324123962254866\n",
       "\\item -0.492588302939271\n",
       "\\item 0.324308230052107\n",
       "\\item -0.291464411643121\n",
       "\\item -1.1691381575818\n",
       "\\item 8.49776941149641\n",
       "\\item -1.49842683067686\n",
       "\\item -0.388859260082862\n",
       "\\item 0.214556943753397\n",
       "\\item 0.090958013078656\n",
       "\\item 0.0659576362537988\n",
       "\\item 0.0753863540885256\n",
       "\\end{enumerate*}\n",
       "\n",
       "\\end{description}\n"
      ],
      "text/markdown": [
       "$var_psi\n",
       ":   1.83281839903412\n",
       "$eif\n",
       ":   1. -0.372921672333097\n",
       "2. -0.324246625667895\n",
       "3. -1.28020859945993\n",
       "4. -1.08242807340988\n",
       "5. -0.520360059564868\n",
       "6. -2.77665824412097\n",
       "7. -1.75785937824695\n",
       "8. -0.0115865998942425\n",
       "9. -0.760688501674998\n",
       "10. -0.224745975492653\n",
       "11. 0.133691894334689\n",
       "12. -0.0623175879709293\n",
       "13. 0.389167783339204\n",
       "14. -2.91221854410309\n",
       "15. 0.446712381668319\n",
       "16. -1.07427380676657\n",
       "17. -0.372751905140712\n",
       "18. -1.83872678581402\n",
       "19. -1.1622951806231\n",
       "20. -1.13666963744829\n",
       "21. -0.738524854032173\n",
       "22. -1.09175369708268\n",
       "23. -1.26358833443541\n",
       "24. -0.481364643303497\n",
       "25. -0.765373194237957\n",
       "26. 0.125872872997511\n",
       "27. -1.02778607325117\n",
       "28. -1.05474823702699\n",
       "29. 0.178263120666102\n",
       "30. -0.619411474579546\n",
       "31. -1.19539393710001\n",
       "32. -0.237266744179227\n",
       "33. 1.35766527807544\n",
       "34. -0.590458673588672\n",
       "35. 0.291732801416383\n",
       "36. -1.39501771150311\n",
       "37. -0.354542849901276\n",
       "38. 1.31060949798089\n",
       "39. 0.495487308188853\n",
       "40. 0.503588861221951\n",
       "41. -0.127013241299687\n",
       "42. -1.10928001105542\n",
       "43. -0.249993738992425\n",
       "44. 1.23952948017547\n",
       "45. -0.052395330570277\n",
       "46. -0.632121997452193\n",
       "47. -1.2595674135327\n",
       "48. 0.115442430164227\n",
       "49. -0.106972147067973\n",
       "50. 0.235607376354369\n",
       "51. 0.992333486527257\n",
       "52. -0.797813209116758\n",
       "53. -1.99097464131076\n",
       "54. -1.51724874785765\n",
       "55. -0.624477815864842\n",
       "56. -2.37933610989996\n",
       "57. -1.16967882788794\n",
       "58. -1.84851082648874\n",
       "59. -0.886500417835579\n",
       "60. -0.794945073127971\n",
       "61. 0.152665131597709\n",
       "62. -2.61889443585171\n",
       "63. -0.38217018238659\n",
       "64. -1.05806161263887\n",
       "65. -0.0682956914372747\n",
       "66. -1.0078467754996\n",
       "67. 0.036664614482167\n",
       "68. -0.435516332764412\n",
       "69. 0.0704412486361709\n",
       "70. 0.181877174720244\n",
       "71. 0.717919545666127\n",
       "72. 0.505658881687694\n",
       "73. 0.336839655356745\n",
       "74. -0.858566614804691\n",
       "75. -2.19770019207986\n",
       "76. -2.64719713010457\n",
       "77. -0.866135315020671\n",
       "78. -1.4592874153835\n",
       "79. 0.767757555221814\n",
       "80. -0.986174169958301\n",
       "81. 0.372397762236261\n",
       "82. -0.250976655578385\n",
       "83. 0.281714836334476\n",
       "84. 0.0359571075030972\n",
       "85. -0.851039274099525\n",
       "86. -0.0130256385186874\n",
       "87. -0.0900046351697245\n",
       "88. -2.75816247166997\n",
       "89. -0.324123962254866\n",
       "90. -0.492588302939271\n",
       "91. 0.324308230052107\n",
       "92. -0.291464411643121\n",
       "93. -1.1691381575818\n",
       "94. 8.49776941149641\n",
       "95. -1.49842683067686\n",
       "96. -0.388859260082862\n",
       "97. 0.214556943753397\n",
       "98. 0.090958013078656\n",
       "99. 0.0659576362537988\n",
       "100. 0.0753863540885256\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "$var_psi\n",
       "[1] 1.832818\n",
       "\n",
       "$eif\n",
       "  [1] -0.37292167 -0.32424663 -1.28020860 -1.08242807 -0.52036006 -2.77665824\n",
       "  [7] -1.75785938 -0.01158660 -0.76068850 -0.22474598  0.13369189 -0.06231759\n",
       " [13]  0.38916778 -2.91221854  0.44671238 -1.07427381 -0.37275191 -1.83872679\n",
       " [19] -1.16229518 -1.13666964 -0.73852485 -1.09175370 -1.26358833 -0.48136464\n",
       " [25] -0.76537319  0.12587287 -1.02778607 -1.05474824  0.17826312 -0.61941147\n",
       " [31] -1.19539394 -0.23726674  1.35766528 -0.59045867  0.29173280 -1.39501771\n",
       " [37] -0.35454285  1.31060950  0.49548731  0.50358886 -0.12701324 -1.10928001\n",
       " [43] -0.24999374  1.23952948 -0.05239533 -0.63212200 -1.25956741  0.11544243\n",
       " [49] -0.10697215  0.23560738  0.99233349 -0.79781321 -1.99097464 -1.51724875\n",
       " [55] -0.62447782 -2.37933611 -1.16967883 -1.84851083 -0.88650042 -0.79494507\n",
       " [61]  0.15266513 -2.61889444 -0.38217018 -1.05806161 -0.06829569 -1.00784678\n",
       " [67]  0.03666461 -0.43551633  0.07044125  0.18187717  0.71791955  0.50565888\n",
       " [73]  0.33683966 -0.85856661 -2.19770019 -2.64719713 -0.86613532 -1.45928742\n",
       " [79]  0.76775756 -0.98617417  0.37239776 -0.25097666  0.28171484  0.03595711\n",
       " [85] -0.85103927 -0.01302564 -0.09000464 -2.75816247 -0.32412396 -0.49258830\n",
       " [91]  0.32430823 -0.29146441 -1.16913816  8.49776941 -1.49842683 -0.38885926\n",
       " [97]  0.21455694  0.09095801  0.06595764  0.07538635\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_eif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference based on the EIF\n",
    "\n",
    "Recall that the asymptotic distribution of TML estimators has been studied thoroughly:\n",
    "$$\\psi_n - \\psi_0 = (P_n - P_0) \\cdot D(\\bar{Q}_n^*, g_n) + R(\\hat{P}^*, P_0),$$\n",
    "which, provided the following two conditions:\n",
    "\n",
    "1. If $D(\\bar{Q}_n^*, g_n)$ converges to $D(P_0)$ in $L_2(P_0)$ norm, and\n",
    "2. the size of the class of functions considered for estimation of $\\bar{Q}_n^*$ and $g_n$ is bounded (technically, $\\exists \\mathcal{F}$ st $D(\\bar{Q}_n^*, g_n) \\in \\mathcal{F}$ *__whp__*, where $\\mathcal{F}$ is a Donsker class),\n",
    "\n",
    "readily admits the conclusion that $\\psi_n - \\psi_0 = (P_n - P_0) \\cdot D(P_0) + R(\\hat{P}^*, P_0)$.\n",
    "\n",
    "Under the additional condition that the remainder term $R(\\hat{P}^*, P_0)$ decays as $o_P \\left( \\frac{1}{\\sqrt{n}} \\right),$ we have that $\\psi_n - \\psi_0 = (P_n - P_0) \\cdot D(P_0) + o_P \\left( \\frac{1}{\\sqrt{n}} \\right),$ which, by a central limit theorem, establishes a Gaussian limiting distribution for the estimator:\n",
    "\n",
    "$$\\sqrt{n}(\\psi_n - \\psi) \\to N(0, V(D(P_0))),$$\n",
    "\n",
    "where $V(D(P_0))$ is the variance of the efficient influence curve (canonical gradient) when $\\psi$ admits an asymptotically linear representation.\n",
    "\n",
    "The above implies that $\\psi_n$ is a $\\sqrt{n}$-consistent estimator of $\\psi$, that it is asymptotically normal (as given above), and that it is locally efficient. This allows us to build Wald-type confidence intervals in a straightforward manner:\n",
    "\n",
    "$$\\psi_n \\pm z_{\\alpha} \\cdot \\frac{\\sigma_n}{\\sqrt{n}},$$\n",
    "\n",
    "where $\\sigma_n^2$ is an estimator of $V(D(P_0))$. The estimator $\\sigma_n^2$ may be obtained using the bootstrap or computed directly via the following\n",
    "\n",
    "$$ \\sigma_n^2 = \\frac{1}{n} \\sum_{i = 1}^{n} D^2(\\bar{Q}_n^*, g_n)(O_i)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference for $\\Psi_{TMLE}$ with the EIF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ci_shifttx <- function(psi, eif, level = 0.95) {\n",
    "    # first, let's get Z_(1 - alpha)\n",
    "    norm_bounds <- c(-1, 1) * abs(qnorm(p = (1 - level) / 2))\n",
    "    \n",
    "    # compute the EIF variance multiplier for the CI\n",
    "    n_obs <- length(eif$eif)\n",
    "    sd_eif <- sqrt(eif$var_psi / n_obs)\n",
    "    \n",
    "    # compute the interval around the point estimate\n",
    "    ci_psi <- norm_bounds * sd_eif + psi\n",
    "    \n",
    "    # set up output CI object\n",
    "    ci_out <- as.data.frame(cbind(ci_psi[1], psi, ci_psi[2]))\n",
    "    colnames(ci_out) <- c(\"lower_ci\", \"est_psi\", \"upper_ci\")\n",
    "    return(ci_out)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>lower_ci</th><th scope=col>est_psi</th><th scope=col>upper_ci</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>0.595979 </td><td>0.8613222</td><td>1.126665 </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lll}\n",
       " lower\\_ci & est\\_psi & upper\\_ci\\\\\n",
       "\\hline\n",
       "\t 0.595979  & 0.8613222 & 1.126665 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "lower_ci | est_psi | upper_ci | \n",
       "|---|\n",
       "| 0.595979  | 0.8613222 | 1.126665  | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  lower_ci est_psi   upper_ci\n",
       "1 0.595979 0.8613222 1.126665"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_ci <- ci_shifttx(psi = est_tmle,\n",
    "                      eif = test_eif,\n",
    "                      level = 0.95)\n",
    "test_ci"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
